{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavya-2k03/Deep-Learning/blob/main/Object_detection_using_YOLO_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mZdWmStrz-B"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import time\n",
        "import cv2\n",
        "from matplotlib import pyplot as pt\n",
        "from os.path import join, isfile\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoNTOcsXsJ2F",
        "outputId": "63d57058-2f0a-4c8f-d2a3-03318bc989f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-07 18:12:17--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/YOLO.zip\n",
            "Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.144.22\n",
            "Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.144.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231559154 (221M) [application/zip]\n",
            "Saving to: ‘YOLO.zip.1’\n",
            "\n",
            "YOLO.zip.1          100%[===================>] 220.83M  11.8MB/s    in 21s     \n",
            "\n",
            "2022-07-07 18:12:39 (10.5 MB/s) - ‘YOLO.zip.1’ saved [231559154/231559154]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/YOLO.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAyCZwgpsRdO",
        "outputId": "c7254831-1035-47b6-e43f-b4ae94ed1c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  YOLO.zip\n",
            "replace YOLO/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y\n",
            "  inflating: YOLO/.DS_Store          \n",
            "replace __MACOSX/YOLO/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: __MACOSX/YOLO/._.DS_Store  \n",
            "  inflating: YOLO/images/londonxmas2.jpeg  \n",
            "  inflating: __MACOSX/YOLO/images/._londonxmas2.jpeg  \n",
            "  inflating: YOLO/images/coffee_view.jpeg  \n",
            "  inflating: __MACOSX/YOLO/images/._coffee_view.jpeg  \n",
            "  inflating: YOLO/images/coffee.jpg  \n",
            "  inflating: __MACOSX/YOLO/images/._coffee.jpg  \n",
            "  inflating: YOLO/images/iceland_rum.jpeg  \n",
            "  inflating: __MACOSX/YOLO/images/._iceland_rum.jpeg  \n",
            "  inflating: YOLO/images/rot.jpg     \n",
            "  inflating: __MACOSX/YOLO/images/._rot.jpg  \n",
            "  inflating: YOLO/images/tommys_beers.jpeg  \n",
            "  inflating: __MACOSX/YOLO/images/._tommys_beers.jpeg  \n",
            "  inflating: YOLO/images/Volleyball.jpeg  \n",
            "  inflating: __MACOSX/YOLO/images/._Volleyball.jpeg  \n",
            "  inflating: YOLO/images/truck.jpg   \n",
            "  inflating: __MACOSX/YOLO/images/._truck.jpg  \n",
            "  inflating: YOLO/images/flowers.jpeg  \n",
            "  inflating: __MACOSX/YOLO/images/._flowers.jpeg  \n",
            "  inflating: YOLO/yolo/coco.names    \n",
            "  inflating: YOLO/yolo/yolov3.cfg    \n",
            "  inflating: YOLO/yolo/yolov3.weights  \n",
            "  inflating: __MACOSX/YOLO/yolo/._yolov3.weights  \n"
          ]
        }
      ],
      "source": [
        "!unzip YOLO.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_sg4SsjsXU1"
      },
      "outputs": [],
      "source": [
        "#labels ko kholke ek list mei likh rhe hain\n",
        "#labels coco.names mei vertically saved hain, hum unhe list mei (horizontally) save krna chahte hain\n",
        "\n",
        "labels_path=\"/content/YOLO/yolo/coco.names\"\n",
        "labels=open(labels_path).read().strip().split('\\n')\n",
        "#ab hum random numbers se ek matrix generate krenge with 80 rows where each row contains 3 random integers from 0 to 255\n",
        "colors=np.random.randint(0,255,size=(len(labels),3),dtype='uint8')\n",
        "#ab hum yolo v3 ke already trained model ko relode karenge\n",
        "net=cv2.dnn.readNetFromDarknet('/content/YOLO/yolo/yolov3.cfg','/content/YOLO/yolo/yolov3.weights')\n",
        "#now we will set the backend of the model\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1nG_aeptugw"
      },
      "outputs": [],
      "source": [
        "#ab hum images folder mei jo bhi files hain unke naam ek file_s naam ki list mei store karenge\n",
        "file_path='/content/YOLO/images/'\n",
        "file_s=[f for f in listdir(file_path) if isfile(join(file_path,f))]\n",
        "#ab hum for loop lga ke ek ek karke images ko model mei input denge\n",
        "for file in file_s:\n",
        "  image=cv2.imread(file_path+file)\n",
        "  (H,W)=image.shape[:2]\n",
        "  # ab images se blob nikalenge aur model mei denge\n",
        "  # defination of blob -->A Blob, in a sense, is anything that is considered a large object or anything bright in a dark background, in images, \n",
        "  # we can generalize it as a group of pixel values that forms a somewhat colony or a large object that is distinguishable from its background. \n",
        "  # Using image processing, we can detect such blobs in an image\n",
        "  blob=cv2.dnn.blobFromImage(image,1/255,(416,416),swapRB=True,crop=False)\n",
        "  net.setInput(blob)\n",
        "  # net.getUnconnectedOutLayersNames() hume yolov3 ke output layers ke naame dedeta hain\n",
        "  # output layers of yolov3 --> yolo82, yolo94 and yolo106\n",
        "  # yolo_V3 has total 106 layers jisme se 53 layers darnet se li hain and baaaki 53 detection ke liye hain \n",
        "  # hoti hain\n",
        "  out_ln=net.getUnconnectedOutLayersNames()\n",
        "  # Now we will run a forward pass through the network\n",
        "  out_layers=net.forward(out_ln)\n",
        "  # Now we will initialize our lists for our detected bounding boxes, confidences, and classes\n",
        "  confidence_s=[]\n",
        "  class_ids=[]\n",
        "  boxe_s=[]\n",
        "  for output in out_layers:\n",
        "    for detection in output:\n",
        "     # scores detection ke 5th ya 5th se aage waale index se isleye liye hain cause classes ke scores output vector(here detection) mei \n",
        "     # 4th index ke aage se start hote hain\n",
        "     # 0,1,2,3 --> x,y,width,height (x,y represent the coordinates of midpoint of bounding box)\n",
        "     # 4 -->  gives Pc -->probablity of detecting a class\n",
        "     # 5 and 5 onwards ---> probablity of detecting individual class\n",
        "     scores=detection[5:]\n",
        "     #np.argmax gives index having the max value\n",
        "     ids=np.argmax(scores)\n",
        "     confidence=max(scores)\n",
        "     \n",
        "     if confidence >0.75:\n",
        "       # We will now scale the bounding box coordinates relative to the image\n",
        "       box=detection[0:4]*np.array([W,H,W,H])\n",
        "       (centre_x,centre_y,width,height)=box.astype(\"int\")\n",
        "       # now we will get the cordinates (i.e x & y) of bottom left corner of image \n",
        "       x=(centre_x-width/2)\n",
        "       y=(centre_y-height/2)\n",
        "       # ab append karte waqt int mei convert krna bahut zyada zaruri hain warna program nhi chalega(reason nhi pta) & it the same for \n",
        "       # converting confidence in float while appending\n",
        "       boxe_s.append([int(x),int(y),int(width),int(height)])\n",
        "       class_ids.append(ids)\n",
        "       confidence_s.append(float(confidence))\n",
        "\n",
        "  # ab hum multiple bounding box ki problem intersection over union (IOU) se solve krenge\n",
        "  # Non Maximum Suppression (NMS) is a technique used in numerous computer vision tasks.It is a class of algorithms to select one  \n",
        "  # entity (e.g., bounding boxes) out of many overlapping entities. IOU is a part of NMS.\n",
        "  idxs = cv2.dnn.NMSBoxes(boxe_s,confidence_s,0.5,0.3)\n",
        "  if len(idxs)>0:\n",
        "    for i in idxs.flatten():\n",
        "      # now we will get the cordinates (i.e x & y) of bottom left corner of image, since earlier declared x,y (in for loop) are local variables \n",
        "      # isliye humne unhe boxe_s list mei dala(jo ki globally declared hain) taaki hum unhe baad mei list mei se nikal ke use kar ske\n",
        "      (x,y)=boxe_s[i][0],boxe_s[i][1]\n",
        "      (width,height)=boxe_s[i][2],boxe_s[i][3]\n",
        "\n",
        "      colo_r=[int(c) for c in colors[class_ids[i]]]\n",
        "      # rectangle banao\n",
        "      cv2.rectangle(image,(x,y),(x+width,y+height),colo_r,3)\n",
        "      # kausi class yolo ne detect kri hain uske hisab se label choose kro\n",
        "      # give this step some time cause its very crucial and thoghtfull and do remember class is actually a number and label is text( for ex\n",
        "      # person,car,etc.) For example class 8 belons to the label Truck and class 9 belongs to the label Boat , you can check more classes\n",
        "      # by opening coco.names folder inside yolo.(Must open!)\n",
        "      text=\"{}: {:.4f}\".format(labels[class_ids[i]],confidence_s[i])\n",
        "      #text ko image pe daalo\n",
        "      cv2.putText(image,text,(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,colo_r,2)\n",
        "\n",
        "  # image ko show kro       \n",
        "  cv2_imshow(image)    \n",
        "  \n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "3"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Object detection using YOLO_V3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSfBUuhqDEI3fc8nn5hUjI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
