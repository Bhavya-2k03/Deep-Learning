{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_detection_using_YOLO_V4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiMWlg+B5ynkyPCzrRXzA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavya-2k03/Deep-Learning/blob/main/Object_detection_using_YOLO_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sus7QF2LycoA"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import time\n",
        "import cv2\n",
        "from matplotlib import pyplot as pt\n",
        "from os.path import join, isfile\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python==4.4.0.40 --force-reinstall"
      ],
      "metadata": {
        "id": "flxhbnRY7cAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv2. __version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOqZVwcL7PcX",
        "outputId": "ce21b389-5763-4862-979d-350dcdcab12b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.cfg \n",
        "!wget  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
      ],
      "metadata": {
        "id": "CWK5QEMly489"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labels ko kholke ek list mei likh rhe hain\n",
        "#labels coco.names mei vertically saved hain, hum unhe list mei (horizontally) save krna chahte hain\n",
        "\n",
        "labels_path=\"/content/coco.names\"\n",
        "labels=open(labels_path).read().strip().split('\\n')\n",
        "#ab hum random numbers se ek matrix generate krenge with 80 rows where each row contains 3 random integers from 0 to 255\n",
        "colors=np.random.randint(0,255,size=(len(labels),3),dtype='uint8')\n",
        "#ab hum yolo v3 ke already trained model ko relode karenge\n",
        "net=cv2.dnn.readNetFromDarknet('/content/yolov4.cfg','/content/yolov4.weights')\n",
        "#now we will set the backend of the model\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n"
      ],
      "metadata": {
        "id": "HxFg8LE3zAaP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ab hum images folder mei jo bhi files hain unke naam ek file_s naam ki list mei store karenge\n",
        "file_path='/content/Sample photos/'\n",
        "file_s=[f for f in listdir(file_path) if isfile(join(file_path,f))]\n",
        "#ab hum for loop lga ke ek ek karke images ko model mei input denge\n",
        "for file in file_s:\n",
        "  image=cv2.imread(file_path+file)\n",
        "  (H,W)=image.shape[:2]\n",
        "  # ab images se blob nikalenge aur model mei denge\n",
        "  # defination of blob -->A Blob, in a sense, is anything that is considered a large object or anything bright in a dark background, in images, \n",
        "  # we can generalize it as a group of pixel values that forms a somewhat colony or a large object that is distinguishable from its background. \n",
        "  # Using image processing, we can detect such blobs in an image\n",
        "  blob=cv2.dnn.blobFromImage(image,1/255,(416,416),swapRB=True,crop=False)\n",
        "  net.setInput(blob)\n",
        "  # net.getUnconnectedOutLayersNames() hume output layers ke naame dedeta hain\n",
        "  # output layers of yolov4 --> yolo139, yolo150 and yolo161\n",
        "  \n",
        "  out_ln=net.getUnconnectedOutLayersNames()\n",
        "  # print(out_ln)\n",
        "  # print(net.getUnconnectedOutLayers())\n",
        "  # print(len(net.getLayerNames()))\n",
        " \n",
        "\n",
        "  # Now we will run a forward pass through the network\n",
        "  out_layers=net.forward(out_ln)\n",
        "  # Now we will initialize our lists for our detected bounding boxes, confidences, and classes\n",
        "  confidence_s=[]\n",
        "  class_ids=[]\n",
        "  boxe_s=[]\n",
        "  for output in out_layers:\n",
        "   for detection in output:\n",
        "     # scores detection ke 5th ya 5th se aage waale index se isleye liye hain cause classes ke scores output vector(here detection) mei \n",
        "     # 4th index ke aage se start hote hain\n",
        "     # 0,1,2,3 --> x,y,width,height (x,y represent the coordinates of midpoint of bounding box)\n",
        "     # 4 -->  gives Pc -->probablity of detecting a class\n",
        "     # 5 and 5 onwards ---> probablity of detecting individual class\n",
        "     scores=detection[5:]\n",
        "     #np.argmax gives index having the max value\n",
        "     ids=np.argmax(scores)\n",
        "    #  print(scores)\n",
        "     confidence=max(scores)\n",
        "     \n",
        "     if confidence >0.75:\n",
        "       # We will now scale the bounding box coordinates relative to the image\n",
        "       box=detection[0:4]*np.array([W,H,W,H])\n",
        "       (centre_x,centre_y,width,height)=box.astype(\"int\")\n",
        "       # now we will get the cordinates (i.e x & y) of bottom left corner of image \n",
        "       x=(centre_x-width/2)\n",
        "       y=(centre_y-height/2)\n",
        "       # ab append karte waqt int mei convert krna bahut zyada zaruri hain warna program nhi chalega(reason nhi pta) & it the same for \n",
        "       # converting confidence in float while appending\n",
        "       boxe_s.append([int(x),int(y),int(width),int(height)])\n",
        "       class_ids.append(ids)\n",
        "       confidence_s.append(float(confidence))\n",
        "\n",
        "  # ab hum multiple bounding box ki problem intersection over union (IOU) se solve krenge\n",
        "  # Non Maximum Suppression (NMS) is a technique used in numerous computer vision tasks.It is a class of algorithms to select one  \n",
        "  # entity (e.g., bounding boxes) out of many overlapping entities. IOU is a part of NMS.\n",
        "  idxs = cv2.dnn.NMSBoxes(boxe_s,confidence_s,0.5,0.3)\n",
        "  if len(idxs)>0:\n",
        "    for i in idxs.flatten():\n",
        "      # now we will get the cordinates (i.e x & y) of bottom left corner of image, since earlier declared x,y (in for loop) are local variables \n",
        "      # isliye humne unhe boxe_s list mei dala(jo ki globally declared hain) taaki hum unhe baad mei list mei se nikal ke use kar ske\n",
        "      (x,y)=boxe_s[i][0],boxe_s[i][1]\n",
        "      (width,height)=boxe_s[i][2],boxe_s[i][3]\n",
        "\n",
        "      colo_r=[int(c) for c in colors[class_ids[i]]]\n",
        "      # rectangle banao\n",
        "      cv2.rectangle(image,(x,y),(x+width,y+height),colo_r,3)\n",
        "      # kausi class yolo ne detect kri hain uske hisab se label choose kro\n",
        "      # give this step some time cause its very crucial and thoghtfull and do remember class is actually a number and label is text( for ex\n",
        "      # person,car,etc.) For example class 8 belons to the label Truck and class 9 belongs to the label Boat , you can check more classes\n",
        "      # by opening coco.names file.\n",
        "      text=\"{}: {:.4f}\".format(labels[class_ids[i]],confidence_s[i])\n",
        "      #text ko image pe daalo\n",
        "      cv2.putText(image,text,(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,colo_r,2)\n",
        "\n",
        "  # image ko show kro       \n",
        "  cv2_imshow(image)    \n",
        "  "
      ],
      "metadata": {
        "id": "e5FRV_I-zFGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}